{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################################################\n",
    "# Simple Implementation of CycleGAN\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# For Project: CycleGAN for Winter in Singapore\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# Author: GongjieZhang@ntu.edu.sg (Nanyang Technological University, Singapore)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# Prerequisites:\n",
    "#     Ubuntu18.04   python3.7   cuda10.1   numpy1.17.2   matplotlib3.1.1   \n",
    "#     pytorch1.3   torchvision0.4.1   tqdm4.36.1    scikit-image0.16.1\n",
    "# #########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import os\n",
    "import tqdm \n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fixed random seeds for reproducibility\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configs\n",
    "\n",
    "summer_dir = '/home/gongjie/GJ_Research/Summer_Winter_DATASET/summer/'\n",
    "winter_dir = '/home/gongjie/GJ_Research/Summer_Winter_DATASET/winter/'\n",
    "\n",
    "img_size = 512  # training resolution @ 512 x 512\n",
    "\n",
    "batchsize = 1\n",
    "lr_init = 2e-4\n",
    "\n",
    "total_num_iteration = 150000\n",
    "save_every_iter = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & Sampler for Training\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, summer_dir, winter_dir, img_size):\n",
    "        self.S_dir = summer_dir\n",
    "        self.W_dir = winter_dir\n",
    "        self.S_imgs = [filename for filename in os.listdir(summer_dir) if os.path.splitext(filename)[-1] in ('.jpg', '.png') ]\n",
    "        self.W_imgs = [filename for filename in os.listdir(winter_dir) if os.path.splitext(filename)[-1] in ('.jpg', '.png') ]\n",
    "        self.transform = [ torchvision.transforms.Resize(int(img_size*1.15), Image.BICUBIC), \n",
    "                           torchvision.transforms.RandomCrop(img_size), \n",
    "                           torchvision.transforms.RandomHorizontalFlip(),\n",
    "                           torchvision.transforms.ToTensor(),  #  [0 - 255] --> [0 - 1.0]\n",
    "                           torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "        self.transform = torchvision.transforms.Compose(self.transform)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        summer_img = self.transform(Image.open(os.path.join(self.S_dir ,\n",
    "                                                            self.S_imgs[index % len(self.S_imgs)])).convert('RGB'))\n",
    "        winter_img = self.transform(Image.open(os.path.join(self.W_dir, \n",
    "                                                            self.W_imgs[random.randint(0, len(self.W_imgs) - 1)])).convert('RGB'))\n",
    "        return summer_img, winter_img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.S_dir), len(self.W_dir))\n",
    "\n",
    "\n",
    "class IterationBasedBatchSampler(torch.utils.data.sampler.BatchSampler):\n",
    "    \"\"\"\n",
    "    Wraps a BatchSampler, re-sampling from it until [num_iterations] iterations have been sampled\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_sampler, num_iterations, start_iter=0):\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.num_iterations = num_iterations\n",
    "        self.start_iter = start_iter\n",
    "\n",
    "    def __iter__(self):\n",
    "        iteration = self.start_iter\n",
    "        while iteration <= self.num_iterations:\n",
    "            # if the underlying sampler has a set_epoch method, like\n",
    "            # DistributedSampler, used for making each process see\n",
    "            # a different split of the dataset, then set it\n",
    "            if hasattr(self.batch_sampler.sampler, \"set_epoch\"):\n",
    "                self.batch_sampler.sampler.set_epoch(iteration)\n",
    "            for batch in self.batch_sampler:\n",
    "                iteration += 1\n",
    "                if iteration > self.num_iterations:\n",
    "                    break\n",
    "                yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_iterations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "\n",
    "def img_show(img):\n",
    "    img = img / 2.0 + 0.5     # unnormalize\n",
    "    npimg = img.detach().cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "    \n",
    "def transform_show(img1, img2):\n",
    "    fig = plt.figure(figsize=(16, 34))\n",
    "    ax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
    "    img_show(img1)\n",
    "    ax = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])\n",
    "    img_show(img2)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Network Architectures\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class Gen(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc=3, output_nc=3, n_residual_blocks=9):\n",
    "        super(Gen, self).__init__()\n",
    "        \n",
    "        # Initial convolution block       \n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_nc, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_nc, 7),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def load(self, model):\n",
    "        self.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    def save(self, model_path):\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "\n",
    "\n",
    "class Dis(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc=3):\n",
    "        super(Dis, self).__init__()\n",
    "\n",
    "        # A bunch of convolutions one after another\n",
    "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(128), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(256), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        model += [  nn.Conv2d(256, 512, 4, padding=1),\n",
    "                    nn.InstanceNorm2d(512), \n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        # FCN classification layer\n",
    "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)\n",
    "    \n",
    "    def load(self, model):\n",
    "        self.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    def save(self, model_path):\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for Loss Functions for Network Optimizations\n",
    "\n",
    "MSELoss = torch.nn.MSELoss()\n",
    "L1Loss = torch.nn.L1Loss()\n",
    "\n",
    "def MSErealTargetLoss(x):\n",
    "    target = torch.cuda.FloatTensor(x.shape[0], 1).fill_(1.0)\n",
    "    return MSELoss(x, target)\n",
    "    \n",
    "\n",
    "def MSEfakeTargetLoss(x):\n",
    "    target = torch.cuda.FloatTensor(x.shape[0], 1).fill_(0.0)\n",
    "    return MSELoss(x, target)\n",
    "\n",
    "\n",
    "def cycleLoss(a, a_):\n",
    "    return L1Loss(a, a_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LambdaLR Scheduler Definition\n",
    "\n",
    "class LambdaLR():\n",
    "    def __init__(self, n_total, decay_start):\n",
    "        assert ((n_total - decay_start) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_total = n_total\n",
    "        self.decay_start = decay_start\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch - self.decay_start)/(self.n_total - self.decay_start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Buffer -- A trick for CycleGAN Optimization\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0)\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Training Scheme \n",
    "# (Can be skipped if model has already been trained.)\n",
    "\n",
    "# Initialize generators and discriminators\n",
    "genS2W = Gen() \n",
    "genW2S = Gen()\n",
    "disS = Dis()\n",
    "disW = Dis()\n",
    "\n",
    "genS2W.apply(weights_init)\n",
    "genW2S.apply(weights_init)\n",
    "disS.apply(weights_init)\n",
    "disW.apply(weights_init)\n",
    "\n",
    "genS2W.cuda()\n",
    "genW2S.cuda()\n",
    "disS.cuda()\n",
    "disW.cuda()\n",
    "\n",
    "# Optimizers & LR schedulers\n",
    "optG = torch.optim.Adam(itertools.chain(genS2W.parameters(), genW2S.parameters()), lr=lr_init, betas=(0.5, 0.999))\n",
    "optD_S = torch.optim.Adam(disS.parameters(), lr=lr_init, betas=(0.5, 0.999))\n",
    "optD_W = torch.optim.Adam(disW.parameters(), lr=lr_init, betas=(0.5, 0.999))\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optG, lr_lambda=LambdaLR(total_num_iteration, total_num_iteration//1.5).step)\n",
    "lr_scheduler_D_S = torch.optim.lr_scheduler.LambdaLR(optD_S, lr_lambda=LambdaLR(total_num_iteration, total_num_iteration//1.5).step)\n",
    "lr_scheduler_D_W = torch.optim.lr_scheduler.LambdaLR(optD_W, lr_lambda=LambdaLR(total_num_iteration, total_num_iteration//1.5).step)\n",
    "\n",
    "dataset = ImageDataset(summer_dir, winter_dir, img_size)\n",
    "sampler = torch.utils.data.RandomSampler(dataset)\n",
    "batch_sampler = torch.utils.data.sampler.BatchSampler(sampler=sampler, batch_size=batchsize, drop_last=True)\n",
    "batch_sampler = IterationBasedBatchSampler(batch_sampler, num_iterations=total_num_iteration)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, num_workers=6, batch_sampler=batch_sampler, pin_memory=True)\n",
    "\n",
    "fake_S_buffer = ReplayBuffer()\n",
    "fake_W_buffer = ReplayBuffer()\n",
    "\n",
    "writer = SummaryWriter('outputs')  # specify directory to store visualization outputs\n",
    "\n",
    "for iteration, (S_imgs, W_imgs) in tqdm.tqdm(enumerate(train_loader)):\n",
    "\n",
    "    S_imgs, W_imgs = S_imgs.cuda(), W_imgs.cuda()\n",
    "\n",
    "    optG.zero_grad()\n",
    "    \n",
    "    # Summer to Winter, then Winter to Summer\n",
    "    identity_W = genS2W(W_imgs)\n",
    "    faked_W = genS2W(S_imgs) \n",
    "    restored_S = genW2S(faked_W)\n",
    "    \n",
    "    # Winter to Summer, then Summer to Winter\n",
    "    identity_S = genW2S(S_imgs)\n",
    "    faked_S = genW2S(W_imgs) \n",
    "    restored_W = genS2W(faked_S)\n",
    "\n",
    "    # compute Adv and cyclic losses, and their updates\n",
    "    AdvLossS = MSErealTargetLoss(disS(faked_S))\n",
    "    AdvLossW = MSErealTargetLoss(disW(faked_W))\n",
    "    CycleLoss1 = cycleLoss(S_imgs, restored_S) * 10.0\n",
    "    CycleLoss2 = cycleLoss(W_imgs, restored_W) * 10.0\n",
    "    loss_G = AdvLossS + AdvLossW + CycleLoss1 + CycleLoss2\n",
    "    loss_G.backward()\n",
    "    optG.step()\n",
    "\n",
    "    # Dis losses and their updates\n",
    "    optD_S.zero_grad()\n",
    "    DisLossS = (MSEfakeTargetLoss(disS(fake_S_buffer.push_and_pop(faked_S).detach())) + MSErealTargetLoss(disS(S_imgs))) * 0.5\n",
    "    DisLossS.backward()\n",
    "    optD_S.step()\n",
    "\n",
    "    optD_W.zero_grad()\n",
    "    DisLossW = (MSEfakeTargetLoss(disW(fake_W_buffer.push_and_pop(faked_W).detach())) + MSErealTargetLoss(disW(W_imgs))) * 0.5\n",
    "    DisLossW.backward()\n",
    "    optD_W.step()\n",
    "    \n",
    "    cntAdvLoss = AdvLossS.item() + AdvLossW.item()\n",
    "    cntCycleLoss = CycleLoss1.item() + CycleLoss2.item()\n",
    "    cntGenLoss = loss_G.item()\n",
    "    \n",
    "    cntDisLossS = DisLossS.item()\n",
    "    cntDisLossW = DisLossW.item()\n",
    "    cntDisLoss = cntDisLossS + cntDisLossW\n",
    "    \n",
    "    # Log training procedure\n",
    "    writer.add_scalar('AdvLoss', cntAdvLoss, iteration+1)\n",
    "    writer.add_scalar('CycleLoss', cntCycleLoss, iteration+1)\n",
    "    writer.add_scalar('Loss_G', cntGenLoss, iteration+1)\n",
    "    \n",
    "    writer.add_scalar('DisLossS', cntDisLossS, iteration+1)\n",
    "    writer.add_scalar('DisLossW', cntDisLossW, iteration+1)\n",
    "    writer.add_scalar('Loss_D', cntDisLoss, iteration+1)\n",
    "    \n",
    "    # Save model and outputs\n",
    "    if (iteration+1) % save_every_iter == 0:\n",
    "        genS2W.save('./s2w_' + \"%06d\" % (iteration+1) + '.pth')\n",
    "        genW2S.save('./w2s_' + \"%06d\" % (iteration+1) + '.pth')\n",
    "    \n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_S.step()\n",
    "    lr_scheduler_D_W.step()\n",
    "    \n",
    "print('Training Completed. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for Inference\n",
    "\n",
    "class ImageDatasetForInference(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, summer_dir, img_size):\n",
    "        self.S_dir = summer_dir\n",
    "        self.S_imgs = [filename for filename in os.listdir(summer_dir) if os.path.splitext(filename)[-1] in ('.jpg', '.png')]\n",
    "        self.transform = [ torchvision.transforms.Resize(int(img_size), Image.BICUBIC), \n",
    "                           torchvision.transforms.ToTensor(),  #  [0 - 255] --> [0 - 1.0] and To Tensor\n",
    "                           torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "        self.transform = torchvision.transforms.Compose(self.transform)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(Image.open(os.path.join(self.S_dir ,\n",
    "                                                      self.S_imgs[(index) % len(self.S_imgs)])).convert('RGB'))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.S_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Configs\n",
    "\n",
    "img_size = 1024  # inference at resolution of 1024 x 1024\n",
    "img_num = 1335\n",
    "model_dir = 's2w_150000.pth'\n",
    "img_dir = '/home/gongjie/GJ_Research/Summer_Winter_DATASET/sg/'\n",
    "store_dir = './generated_size' + str(img_size) + '_model' + str(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inference Scheme\n",
    "\n",
    "dataset = ImageDatasetForInference(img_dir, img_size)\n",
    "model = Gen().cuda()\n",
    "model.load(model_dir)\n",
    "model.eval()\n",
    "if not os.path.exists(store_dir):\n",
    "    os.mkdir(store_dir)\n",
    "     \n",
    "with torch.no_grad():\n",
    "    for i in tqdm.tqdm(range(img_num)):\n",
    "        img = dataset.__getitem__(i).cuda().unsqueeze(0)\n",
    "        gen_img = model(img).squeeze(0)\n",
    "        fig = transform_show(img.squeeze(0), gen_img)\n",
    "        plt.savefig(os.path.join(store_dir, \"%04d\" % (i+1) + '.jpg'))\n",
    "        plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
